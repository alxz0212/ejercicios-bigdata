# GU√çA R√ÅPIDA DE DESPLIEGUE DESDE CERO (CHEAT SHEET)
**Proyecto:** Big Data & "Gran Juego" (Pipeline + ML + Dashboard)

---

## **PRERREQUISITOS**
1. Tener **Docker Desktop** instalado y corriendo.
2. Tener el c√≥digo fuente descargado.
3. Abrir una terminal (PowerShell o CMD) y navegar a la carpeta del proyecto:
   ```powershell
   cd entregas/trabajo_final/Alexis_Mendoza
   ```
   > **IMPORTANTE:** Todos los comandos deben ejecutarse desde esta carpeta.

---

## **PASO 0: LEVANTAR LA INFRAESTRUCTURA** üèóÔ∏è
Enciende los servidores (Jupyter, Spark Master/Worker, Postgres). El flag `-d` lo hace en segundo plano.

**Comando:**
```bash
docker-compose up -d --build
```

Espera a que se construya la imagen y arranque todo.
> **NOTA:** La primera vez puede tardar entre 5 y 10 minutos (descarga de im√°genes). Las siguientes veces ser√° casi instant√°neo.
>
> *Docker debe estar abierto antes de ejecutar cualquier comando*

---

## **PASO 1: PREPARACI√ìN DE DATOS (IMPORTANTE)** üì•
Antes de iniciar, necesitas el dataset "Quality of Government" (Time-Series).
1. Crea la carpeta donde ir√°n los datos raw.
2. Coloca el archivo `qog_std_ts_jan26.csv` dentro.

**Comando (PowerShell):**
```bash
docker exec jupyter_lab python /home/jovyan/work/src/download_data.py
```

---

## **PASO 2: INSTALAR DEPENDENCIAS (Autom√°tico)** üì¶
Las dependencias (Streamlit, PySpark, etc.) ahora se instalan autom√°ticamente al levantar el contenedor gracias al Dockerfile y `requirements.txt`.
**¬°Ya no necesitas ejecutar nada aqu√≠!**

---

## **PASO 3: EJECUTAR EL PIPELINE DE DATOS (ETL)** ‚öôÔ∏è
Procesa el CSV crudo y genera el archivo Parquet limpio.

**Comando:**
```bash
docker exec jupyter_lab python /home/jovyan/work/src/pipeline.py
```
Deber√≠as ver "Proceso ETL completado con √©xito".

---

## **PASO 4: ENTRENAR MODELO Y GENERAR GR√ÅFICOS (SPARK)** üìä
Calcula las correlaciones y entrena el Random Forest con PySpark.

**Comando:**
```bash
docker exec jupyter_lab spark-submit /home/jovyan/work/src/analysis.py
```
Esto generar√° las im√°genes `.png` en la carpeta `notebooks/`.

---

## **PASO 5: EJECUTAR AN√ÅLISIS ECONOM√âTRICO (HAUSMAN)** üìâ
Calcula Efectos Fijos vs Aleatorios para validar la hip√≥tesis.

**Comando:**
```bash
docker exec jupyter_lab python /home/jovyan/work/src/econometric_analysis.py
```
Genera reporte en `notebooks/hausman_results.txt`.

---

## **PASO 6: LANZAR LA "SUPER WEB" (DASHBOARD)** üöÄ
Inicia el servidor de Streamlit en segundo plano.

**Comando (Versi√≥n Cl√°sica):**
```bash
docker exec -d -w /home/jovyan/work/src jupyter_lab streamlit run app_streamlit.py
```

**Comando (Versi√≥n PRO 3D) üåü:**
```bash
docker exec -d -w /home/jovyan/work/src jupyter_lab streamlit run app_streamlit_pro.py
```

---

## **PASO 7: GENERAR DASHBOARD HTML (PORT√ÅTIL)** üåç
Genera un archivo HTML √∫nico con todos los gr√°ficos incrustados, ideal para enviar por correo o entregar sin necesidad de que el receptor tenga Docker instalado.

**Comando:**
```bash
docker exec jupyter_lab python /home/jovyan/work/src/export_dashboard.py
```
El archivo se generar√° en `dashboard.html`.

---

## **ACCESOS** üåê

| Servicio | URL | Notas |
|----------|-----|-------|
| **DASHBOARD (Streamlit)** | http://localhost:8501 | Web interactiva con el Bot IA |
| **JUPYTER LAB** | http://localhost:8888 | Contrase√±a: `bigdata2024` |
| **SPARK MASTER** | http://localhost:8081 | Estado del cluster |
| **SPARK JOB UI** | http://localhost:4040 | Solo funciona **DURANTE** la ejecuci√≥n de scripts |

---

## **C√ìMO APAGAR TODO** üõë
Cuando termines, elimina todo para limpiar tu m√°quina.

**Comando:**
```bash
docker-compose down
```

---

## **C√ìMO ACTUALIZAR EN GITHUB** üêô
Si haces cambios en el c√≥digo y quieres subirlos a tu repositorio:

1. **Verificar estado:**
   ```bash
   git status
   ```

2. **Agregar cambios:**
   ```bash
   git add .
   ```

3. **Guardar cambios:**
   ```bash
   git commit -m "Mensaje explicando tus cambios"
   ```

4. **Subir a GitHub:**
   ```bash
   git push origin main
   ```

5. **(Opcional) Traer cambios remotos:**
   ```bash
   git pull origin main
   ```

---

## **TROUBLESHOOTING / EXTRAS** üõ†Ô∏è

### ¬øEl Dashboard no se actualiza?
A veces Streamlit no detecta cambios. Para reiniciarlo:
1. Mata el proceso:
   ```bash
   docker exec jupyter_lab pkill -f streamlit
   ```
2. In√≠cialo de nuevo:
   ```bash
   docker exec -d jupyter_lab streamlit run /home/jovyan/work/src/app_streamlit.py
   ```

### ¬øError: "Ports are not available"?
Si el puerto (8080, 8081, etc.) est√° ocupado:
1. Abre `docker-compose.yml`.
2. Busca los `ports`.
3. Cambia el n√∫mero de la IZQUIERDA. (Ej: `"8085:8080"`).
4. Ejecuta: `docker-compose up -d`.

---

## **EJECUCI√ìN RECURRENTE** üîÑ
Si ya instalaste todo una vez:

1. **Abrir Docker Desktop.**
2. **Levantar servicios:**
   ```bash
   docker-compose up -d
   ```
3. **Lanzar Dashboard:**
   ```bash
   docker exec -d jupyter_lab streamlit run /home/jovyan/work/src/app_streamlit_pro.py
   ```
4. **Ir a:** http://localhost:8501

---

## **SCRIPT AUTOM√ÅTICO** ü§ñ
Si no quieres escribir comandos de Git:
1. Busca el archivo `upload_to_github.bat` en esta misma carpeta.
2. Haz doble clic sobre √©l.
3. Sigue las instrucciones.
