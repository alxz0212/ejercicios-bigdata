# üìòPaso 5: Documentaci√≥n T√©cnica del C√≥digo Fuente

**Proyecto:** Big Data & Geopol√≠tica ("El Gran Juego")
**Alumno:** Daniel Alexis Mendoza Corne
**Fecha:** Febrero 2026

---

## 1. ¬øPor qu√© la carpeta se llama `src`?

`src` es la abreviatura est√°ndar en ingenier√≠a de software para **"Source"** (C√≥digo Fuente).

En proyectos profesionales, es fundamental mantener separado el c√≥digo l√≥gico de otros elementos. Esta estructura garantiza:

- **Orden:** El c√≥digo no se mezcla con la documentaci√≥n (`.md`), la configuraci√≥n (`docker/`) o los datos (`data/`).
- **Seguridad:** Facilita la configuraci√≥n de permisos; por ejemplo, el servidor de producci√≥n solo necesita acceso de lectura a `src`, pero de escritura a `data`.
- **Escalabilidad:** Si el proyecto crece, todo el c√≥digo l√≥gica reside en un √∫nico punto de verdad.

---

## 2. Cat√°logo de Scripts

A continuaci√≥n, se detalla la funci√≥n t√©cnica y de negocio de cada m√≥dulo desarrollado.

### üõ†Ô∏è 1. Infraestructura y Preparaci√≥n

#### `download_data.py`

- **Funci√≥n:** Automatizaci√≥n de Ingesta.
- **Qu√© hace:** Se conecta al repositorio de la Universidad de Gotemburgo, descarga el dataset `.csv` de 68MB y lo coloca en la ruta `data/raw/`.
- **Por qu√© es importante:** Elimina la dependencia de descargas manuales, haciendo que el proyecto sea reproducible en cualquier m√°quina con un solo comando.

#### `verify_spark.py`

- **Funci√≥n:** Test de Integridad (Smoke Test).
- **Qu√© hace:** Intenta iniciar una sesi√≥n de Spark y crear un DataFrame peque√±o en memoria.
- **Por qu√© es importante:** Es el primer script que ejecutamos para validar que el contenedor de Docker y el cluster de Spark est√°n comunic√°ndose correctamente antes de lanzar procesos pesados.

---

### ‚öôÔ∏è 2. Procesamiento de Datos (ETL)

#### `pipeline.py`

- **Funci√≥n:** ETL (Extract, Transform, Load).
- **Tecnolog√≠a:** Apache Spark (PySpark SQL).
- **Flujo de Trabajo:**
  1. **Extract:** Lee el CSV crudo.
  2. **Transform:**
      - Filtra los 5 pa√≠ses del "Gran Juego" (Afganist√°n, Mongolia, C√°ucaso).
      - Crea la variable derivada `subregion`.
      - Castea tipos de datos (Strings a Doubles) para asegurar precisi√≥n matem√°tica.
  3. **Load:** Guarda el resultado limpio en formato **Parquet**.
- **Detalle Pro:** Usamos `.parquet` en lugar de `.csv` porque es un formato columnar comprimido que es mucho m√°s r√°pido para leer en an√°lisis posteriores de Big Data.

#### `ingest_data.py` (M√≥dulo Legado)

- **Funci√≥n:** Conector a Base de Datos Relacional.
- **Qu√© hace:** Estaba dise√±ado para cargar los datos en PostgreSQL.
- **Estado:** Se mantiene como respaldo. Para el an√°lisis principal optamos por el flujo Spark-Parquet por ser m√°s nativo del ecosistema de Big Data que el almacenamiento SQL tradicional.

---

### üß† 3. An√°lisis Avanzado y Resultados

#### `analysis.py`

- **Funci√≥n:** Motor de Machine Learning.
- **Tecnolog√≠a:** Spark MLlib.
- **Qu√© hace:**
  - Carga los datos procesados (Parquet).
  - **Matriz de Correlaci√≥n:** Calcula c√≥mo se relacionan las variables (ej. Gasto Militar vs PIB).
  - **Random Forest:** Entrena un modelo de Inteligencia Artificial compuesto por 100 √°rboles de decisi√≥n para predecir el desarrollo econ√≥mico.
  - **Feature Importance:** Extrae qu√© variables tuvieron m√°s peso en la decisi√≥n del modelo.
- **Salida:** Genera autom√°ticamente los gr√°ficos est√°ticos `.png` en la carpeta `notebooks/`.

#### `econometric_analysis.py`

- **Funci√≥n:** An√°lisis Econom√©trico Riguroso.
- **Tecnolog√≠a:** Librer√≠a `linearmodels` (Python).
- **Qu√© hace:**
  - Ejecuta modelos de regresi√≥n para datos de panel: **Efectos Fijos (Fixed Effects)** y **Efectos Aleatorios (Random Effects)**.
  - Implementa el **Test de Hausman** para determinar cu√°l de los dos modelos es estad√≠sticamente m√°s adecuado (causalidad vs correlaci√≥n).
  - Genera un reporte detallado en `notebooks/hausman_results.txt`.
- **Valor agregado:** Complementa la "caja negra" del Machine Learning (Random Forest) con inferencia estad√≠stica cl√°sica, validando si las caracter√≠sticas √∫nicas de cada pa√≠s sesgan los resultados.

---

### üöÄ 4. Interfaz de Usuario (Frontend)

#### `src/app_streamlit.py` y `src/app_streamlit_pro.py`

Son el Frontend de la aplicaci√≥n.

- **Tecnolog√≠a:** Streamlit.
- **Funciones:**
  - Cargar el Parquet procesado.
  - Generar gr√°ficos interactivos con Plotly.
  - **Pro Version (Madrid Elite Edition) üåü:**
  - Est√©tica **Glassmorphism** premium (efecto cristal).
  - Globo 3D, radar charts y HUD din√°mico.
  - **AI Strategic Advisor:** Motor de an√°lisis autom√°tico que genera informes de riesgo y oportunidad en tiempo real.
  - **Modo Presentaci√≥n:** Navegaci√≥n por diapositivas ideal para defensas oficiales.
  - Es la "cara" del proyecto, transformando el c√≥digo t√©cnico en un producto visual consumible por un usuario final.

---

## 3. Diagrama de Flujo de Datos

```mermaid
graph TD
    %% Estilos
    classDef source fill:#f9f,stroke:#333,stroke-width:2px;
    classDef script fill:#bbf,stroke:#333,stroke-width:2px,color:black;
    classDef data fill:#dfd,stroke:#333,stroke-width:2px,color:black;
    classDef output fill:#fd9,stroke:#333,stroke-width:2px,color:black,stroke-dasharray: 5 5;

    subgraph INGESTA ["üì° Ingesta de Datos"]
        A["‚òÅÔ∏è Internet / Repo QoG"]:::source
        Script1{{"üêç download_data.py"}}:::script
    end

    subgraph PROCESAMIENTO ["‚öôÔ∏è Procesamiento & An√°lisis"]
        Script2{{"‚ö° pipeline.py"}}:::script
        Script3{{"üß† analysis.py"}}:::script
        Script5{{"üìâ econometric_analysis.py"}}:::script
    end

    subgraph ALMACENAMIENTO ["üíæ Almacenamiento"]
        B[("üìÑ Raw CSV")]:::data
        C[("üì¶ Clean Parquet")]:::data
    end

    subgraph VISUALIZACION ["üìä Consumo & UI"]
        Script4{{"üöÄ app_streamlit_pro.py"}}:::script
        D["üìà Gr√°ficos Est√°ticos .png"]:::output
        E["üñ•Ô∏è Dashboard 3D Interactivo"]:::output
        F["üìÑ Reporte Hausman .txt"]:::output
    end

    %% Relaciones
    A --> Script1
    Script1 --> B
    B --> Script2
    Script2 --> C
    C --> Script3
    C --> Script4
    C --> Script5
    Script3 --> D
    Script4 --> E
    Script5 --> F
```

> [!NOTE]
> **Conclusi√≥n del Flujo de Datos:**  
> Como se observa en el diagrama, el proyecto sigue una arquitectura lineal de Big Data moderna:
>
> 1. **Ingesta:** Los datos se capturan autom√°ticamente de internet (`download_data.py`).
> 2. **Procesamiento:** Se limpian y estructuran en Spark (`pipeline.py`), guard√°ndose en formato eficiente **Parquet**.
> 3. **Consumo:** A partir del dato limpio, se derivan tres productos finales: An√°lisis ML (`analysis.py`), Validaci√≥n Estad√≠stica (`econometric_analysis.py`) y Visualizaci√≥n Interactiva (`app_streamlit_pro.py`).
>
> Esta estructura modular asegura que si cambiamos la fuente de datos, solo tocamos el script de _Ingesta_, sin romper el Dashboard final.

---

## 4. DevOps y Documentaci√≥n (Automatizaci√≥n) üèóÔ∏è

Para desplegar este sitio web, utilizamos un flujo de trabajo automatizado que se basa en el formato **.yml** (YAML).

### ¬øQu√© es un archivo .yml / .yaml?

Es un formato de "serializaci√≥n de datos" dise√±ado para ser le√≠do f√°cilmente por humanos.

- **Configuraci√≥n:** Se usa casi universalmente en DevOps para configurar herramientas.
- **Indentaci√≥n:** Se basa estrictamente en espacios (niveles). ¬°Un espacio de m√°s o de menos puede invalidar el archivo!
- **Estructura:** Funciona mediante pares de `clave: valor`.

### Relaci√≥n entre los elementos clave

#### 1. `mkdocs.yml` (El Cerebro üß†)

- **Ubicaci√≥n:** Ra√≠z del proyecto.
- **Funci√≥n:** Es el archivo central de configuraci√≥n de tu sitio web.
- **Navegaci√≥n & index.md:** Aqu√≠ es donde asocias tus archivos Markdown con el men√∫ de la web. Por ejemplo:
  - `- "üè† Inicio": index.md`
  - Esto le dice a MkDocs que cuando alguien haga clic en "Inicio", debe mostrar el contenido de `index.md`.
- **Est√©tica:** Aqu√≠ defines si el sitio es oscuro (Slate) o claro, los colores primarios y los iconos.

#### 2. `.github/workflows/deploy_docs.yml` (El Robot üë∑)

- **Ubicaci√≥n:** `.github/workflows/`.
- **Funci√≥n:** Automatizaci√≥n del Despliegue (CI/CD).
- **Flujo:** Cada vez que haces un `git push` a la rama `main`, este "robot" se despierta y:
  1. Lee el `mkdocs.yml` para entender la estructura.
  2. Procesa el `index.md` y los dem√°s archivos `.md`.
  3. Transforma todo en c√≥digo HTML real (el sitio web).
  4. Lo publica en GitHub Pages.

#### 3. `index.md` (La Puerta de Entrada üö™)

- Es el archivo de contenido m√°s importante. Es la "Home" de tu documentaci√≥n.
- Sin un archivo designado como inicio en el `mkdocs.yml`, la web no tendr√≠a una p√°gina de aterrizaje clara.
