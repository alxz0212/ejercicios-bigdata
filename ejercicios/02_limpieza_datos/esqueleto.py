"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HEADER ACADÃ‰MICO - EJERCICIOS BIG DATA CON PYTHON
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Alumno: __________________________ (Escribe tu nombre aquÃ­)
Fecha:  __________________________
Ejercicio: 02 - Limpieza de Datos QoG
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import dask.dataframe as dd
import pandas as pd
from pathlib import Path

# Agregar directorio raÃ­z al path para importar utils si fuera necesario
BASE_DIR = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(BASE_DIR))

# ConfiguraciÃ³n de Rutas
INPUT_FILE = BASE_DIR / "datos" / "qog" / "qog_std_ts_jan24.csv"
OUTPUT_DIR = BASE_DIR / "datos" / "qog" / "processed"
OUTPUT_FILE = OUTPUT_DIR / "qog_limpio.parquet"

def clean_qog_dataset():
    """
    FunciÃ³n principal para limpiar el dataset Quality of Government.
    """
    
    # 1. VERIFICACIÃ“N
    if not INPUT_FILE.exists():
        print(f"âŒ Error: No se encuentra el archivo {INPUT_FILE}")
        print("   Ejecuta: python scripts/download_datasets.py --dataset qog")
        return

    print(f"ğŸ“– Cargando dataset: {INPUT_FILE}")
    
    # 2. CARGA (TODO: Completa la carga con Dask)
    # Pista: dd.read_csv(str(INPUT_FILE))
    # df = ... 
    df = dd.read_csv(str(INPUT_FILE)) # <--- Descomenta y ajusta si es necesario

    # 3. SELECCIÃ“N Y RENOMBRADO (TODO)
    # Selecciona solo estas columnas: ccode, cname, year, vdem_polyarchy, wdi_gdppc
    # RenÃ³bralas a: codigo_pais, nombre_pais, anio, indice_democracia, pib_per_capita
    
    selected_columns = {
        'ccode': 'codigo_pais',
        # ... TODO: Completa el diccionario ...
    }
    
    # df = df[list(selected_columns.keys())]
    # df = df.rename(columns=selected_columns)

    # 4. FILTRADO (TODO)
    # QuÃ©date solo con aÃ±os >= 2000
    # df = df[ ... ]

    # 5. LIMPIEZA DE NULOS (TODO)
    # Elimina filas donde 'nombre_pais' sea nulo (NaN)
    # df = df.dropna(subset=['nombre_pais'])

    # 6. CONVERSIÃ“N DE TIPOS (OpciÃ³n Avanzada)
    # Asegura que 'anio' sea entero
    # df['anio'] = df['anio'].astype(int)

    # 7. GUARDADO
    print(f"ğŸ’¾ Guardando resultado en: {OUTPUT_FILE}")
    
    # Crear carpeta destino si no existe
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # Guardar en Parquet (Usamos PyArrow)
    try:
        # TODO: Descomenta la lÃ­nea siguiente para guardar
        # df.to_parquet(str(OUTPUT_FILE), engine='pyarrow', write_index=False, compression='snappy')
        print("âœ… Proceso finalizado con Ã©xito.")
        
        # ValidaciÃ³n rÃ¡pida (Esto se ejecutarÃ¡ realmente aquÃ­ al llamar a compute/head)
        print("\nğŸ“Š Vista previa de los datos procesados:")
        print(df.head())
        
    except Exception as e:
        print(f"âŒ Error al guardar/procesar: {e}")

if __name__ == "__main__":
    clean_qog_dataset()
