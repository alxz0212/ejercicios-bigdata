# Exercises

Complete list of all available exercises in the course.

---

## Exercise Roadmap

### Module 1: Databases

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 1.1 | [Introduction to SQLite](01-introduccion-sqlite.md) | SQLite + Pandas | Basic | Available |
| 2.1 | [PostgreSQL HR](02-postgresql-hr.md) | PostgreSQL | Intermediate | Available |
| 2.2 | [PostgreSQL Gardening](03-postgresql-jardineria.md) | PostgreSQL | Intermediate | Available |
| 2.3 | [SQLite to PostgreSQL Migration](04-migracion-sqlite-postgresql.md) | PostgreSQL + Python | Intermediate | Available |
| 3.1 | [Oracle HR](05-oracle-hr.md) | Oracle Database | Advanced | Available |
| 5.1 | [Excel/Python Analysis](06-analisis-excel-python.md) | Pandas + Excel | Basic | Available |

### Module 2: Data Cleaning and ETL

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 02 | [ETL Pipeline QoG](02-pipeline-etl-qog.md) | PostgreSQL + Pandas | Advanced | Available |

### Module 3: Distributed Processing

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 03 | [Distributed Processing with Dask](03-procesamiento-distribuido.md) | Dask + Parquet | Intermediate | Available |

### Module 4: Machine Learning

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 04 | [Machine Learning (PCA, K-Means)](04-machine-learning.md) | Scikit-Learn, PCA, K-Means | Advanced | Available |
| 04.2 | [Transfer Learning Flowers](04-machine-learning.md#ejercicio-42-transfer-learning-clasificacion-de-flores) | TensorFlow, MobileNetV2 | Advanced | Available |
| ARIMA | [Time Series ARIMA/SARIMA](07-series-temporales-arima.md) | statsmodels, Box-Jenkins | Advanced | Available |

### Module 5: NLP and Text Mining

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 05 | [NLP and Text Mining](05-nlp-mining.md) | NLTK, TF-IDF, Jaccard, Sentiment | Advanced | Available |

### Module 6: Panel Data Analysis

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 06 | [Panel Data Analysis](08-panel-data.md) | linearmodels, Panel OLS, Altair | Advanced | Available |

### Module 7: Big Data Infrastructure

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 07 | [Big Data Infrastructure](07-infraestructura-bigdata.md) | Docker Compose, Apache Spark | Intermediate-Advanced | Available |

### Module 8: Streaming with Kafka

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 08 | [Streaming with Kafka](08-streaming-kafka.md) | Apache Kafka, Spark Streaming, KRaft | Advanced | Available |

### Module 9: Cloud with LocalStack

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| 09 | [Cloud with LocalStack](09-cloud-localstack.md) | LocalStack, Terraform, AWS | Advanced | Available |

### Capstone Project

| # | Exercise | Technology | Level | Status |
|---|----------|------------|-------|--------|
| TF | [Capstone Integrative Project](06-trabajo-final-capstone.md) | Docker + Spark + PostgreSQL + QoG | Advanced | Available |

---

## MODULE 1: Databases

### [Exercise 1.1: Introduction to SQLite](01-introduccion-sqlite.md)

!!! info "Details"
    - **Level:** Basic
    - **Dataset:** NYC Taxi (10MB sample)
    - **Technologies:** SQLite, Pandas

**What you'll learn:**

- Load CSV data into a SQLite database
- Basic SQL queries (SELECT, WHERE, GROUP BY)
- Optimization with indexes
- Export results to CSV

[View Full Exercise](01-introduccion-sqlite.md){ .md-button .md-button--primary }

---

### [Exercise 2.1: PostgreSQL with HR Database](02-postgresql-hr.md)

!!! info "Details"
    - **Level:** Intermediate
    - **Database:** HR (Human Resources) from Oracle
    - **Technologies:** PostgreSQL, SQL

**What you'll learn:**

- Install and configure PostgreSQL
- Load databases from SQL scripts
- Complex queries with multiple JOINs
- PostgreSQL-specific functions

[View Full Exercise](02-postgresql-hr.md){ .md-button }

---

### [Exercise 2.2: PostgreSQL Gardening](03-postgresql-jardineria.md)

!!! info "Details"
    - **Level:** Intermediate
    - **Database:** Gardening sales system
    - **Technologies:** PostgreSQL, Window Functions

**What you'll learn:**

- Sales analysis with SQL
- Complex aggregations (GROUP BY, HAVING)
- Window Functions for rankings
- Materialized views

[View Full Exercise](03-postgresql-jardineria.md){ .md-button }

---

### [Exercise 2.3: SQLite to PostgreSQL Migration](04-migracion-sqlite-postgresql.md)

!!! info "Details"
    - **Level:** Intermediate
    - **Technologies:** SQLite, PostgreSQL, Python

**What you'll learn:**

- Differences between database engines
- Migrate schemas and data
- Adapt data types
- Validate integrity

[View Full Exercise](04-migracion-sqlite-postgresql.md){ .md-button }

---

### [Exercise 3.1: Oracle with HR Database](05-oracle-hr.md)

!!! warning "Advanced"
    - **Level:** Advanced
    - **Database:** HR on native Oracle
    - **Technologies:** Oracle Database, PL/SQL

**What you'll learn:**

- Install Oracle Database XE
- Oracle-specific syntax
- PL/SQL (procedures, functions)
- Sequences and triggers

[View Full Exercise](05-oracle-hr.md){ .md-button }

---

### [Exercise 5.1: Excel/Python Analysis](06-analisis-excel-python.md)

!!! info "Details"
    - **Level:** Basic-Intermediate
    - **Technologies:** Python, Pandas, Excel

**What you'll learn:**

- Read Excel files with Python
- Exploratory Data Analysis (EDA)
- Visualizations with matplotlib/seaborn
- Automate analyses

[View Full Exercise](06-analisis-excel-python.md){ .md-button }

---

## MODULE 2: Data Cleaning and ETL

### [Professional ETL Pipeline - Quality of Government](02-pipeline-etl-qog.md)

!!! info "Details"
    - **Level:** Advanced
    - **Dataset:** QoG (1289 variables, 194+ countries)
    - **Technologies:** PostgreSQL, Pandas, psycopg2

**What you'll learn:**

- Design a modular ETL architecture
- Work with PostgreSQL for longitudinal analysis
- Clean complex datasets (>1000 variables)
- Prepare panel data for econometrics

[View Full Exercise](02-pipeline-etl-qog.md){ .md-button }

---

## MODULE 3: Distributed Processing

### [Distributed Processing with Dask](03-procesamiento-distribuido.md)

!!! info "Details"
    - **Level:** Intermediate
    - **Technologies:** Dask, Parquet, LocalCluster

**What you'll learn:**

- Set up a Local Cluster with Dask
- Read Parquet files in a partitioned manner
- Execute complex aggregations in parallel
- Compare performance vs Pandas

[View Full Exercise](03-procesamiento-distribuido.md){ .md-button }

---

## MODULE 4: Machine Learning

### [Machine Learning in Big Data](04-machine-learning.md)

!!! info "Details"
    - **Level:** Advanced
    - **Technologies:** Scikit-Learn, PCA, K-Means
    - **Scripts:** PCA Iris, FactoMineR, Breast Cancer, Wine, TF-IDF

**What you'll learn:**

- Dimensionality reduction with PCA
- Clustering with K-Means and Hierarchical Clustering
- Principal component interpretation
- Cluster profiling

[View Full Exercise](04-machine-learning.md){ .md-button }

---

### [Transfer Learning: Flower Classification](04-machine-learning.md#ejercicio-42-transfer-learning-clasificacion-de-flores)

!!! info "Details"
    - **Level:** Advanced
    - **Technologies:** TensorFlow, MobileNetV2, Scikit-Learn
    - **Dataset:** TensorFlow Flowers (3,670 images, 5 classes)

**What you'll learn:**

- Transfer Learning with pre-trained networks (ImageNet)
- Embedding extraction with CNNs
- Image classification with traditional ML (KNN, SVM, Random Forest)
- t-SNE visualization of high-dimensional spaces

[View Interactive Dashboard](../dashboards/dashboard_flores.html){ .md-button target="_blank" }

---

### [Time Series: ARIMA/SARIMA](07-series-temporales-arima.md)

!!! info "Details"
    - **Level:** Advanced
    - **Dataset:** AirPassengers (144 observations, 1949-1960)
    - **Technologies:** statsmodels, Box-Jenkins Methodology

**What you'll learn:**

- Complete Box-Jenkins methodology (Identification, Estimation, Diagnostics, Forecasting)
- ARIMA and SARIMA models with seasonality
- ACF/PACF for order identification
- Residual diagnostics and forecasts

[View Full Exercise](07-series-temporales-arima.md){ .md-button }

---

---

## MODULE 5: NLP and Text Mining

### [NLP and Text Mining](05-nlp-mining.md)

!!! info "Details"
    - **Level:** Advanced
    - **Technologies:** NLTK, TF-IDF, Jaccard, Sentiment Analysis
    - **Scripts:** Counting, Cleaning, Sentiment, Similarity

**What you'll learn:**

- Tokenization and text cleaning
- Stopword removal
- Jaccard similarity between documents
- Lexicon-based sentiment analysis

[View Full Exercise](05-nlp-mining.md){ .md-button }

---

## MODULE 6: Panel Data Analysis

### [Panel Data Analysis](08-panel-data.md)

!!! info "Details"
    - **Level:** Advanced
    - **Datasets:** Guns (gun laws), Fatalities (traffic mortality)
    - **Technologies:** linearmodels, Panel OLS, Altair

**What you'll learn:**

- Panel data: country x year structure
- Fixed Effects vs Random Effects
- Two-Way Fixed Effects
- Hausman test for model selection
- Odds Ratios and Marginal Effects

[View Full Exercise](08-panel-data.md){ .md-button }

---

## MODULE 7: Big Data Infrastructure

### [Big Data Infrastructure: Docker and Spark](07-infraestructura-bigdata.md)

!!! info "Details"
    - **Level:** Intermediate-Advanced
    - **Type:** Theoretical-Conceptual with practical examples
    - **Technologies:** Docker, Docker Compose, Apache Spark

**What you'll learn:**

- Docker: containers, images, Dockerfile, orchestration with Compose
- Networks, volumes, healthchecks, production patterns
- Apache Spark: Master-Worker architecture, cluster with Docker
- SparkSession, Lazy Evaluation, DAG, Catalyst optimizer
- Spark + PostgreSQL via JDBC
- From Standalone to production (Kubernetes, EMR, Dataproc)

[View Full Exercise](07-infraestructura-bigdata.md){ .md-button }

---

## MODULE 8: Streaming with Kafka

### [Streaming with Apache Kafka](08-streaming-kafka.md)

!!! info "Details"
    - **Level:** Advanced
    - **Technologies:** Apache Kafka (KRaft), Python, Spark Streaming
    - **API:** USGS Earthquakes (real-time)

**What you'll learn:**

- Kafka architecture: Brokers, Topics, Partitions
- KRaft mode (no ZooKeeper)
- Producers and Consumers in Python
- Spark Structured Streaming
- Real-time alert system

[View Full Exercise](08-streaming-kafka.md){ .md-button }

---

## MODULE 9: Cloud with LocalStack

### [Cloud with LocalStack and Terraform](09-cloud-localstack.md)

!!! info "Details"
    - **Level:** Advanced
    - **Technologies:** LocalStack, Terraform, AWS (S3, Lambda, DynamoDB)
    - **API:** ISS Tracker (real-time)

**What you'll learn:**

- Cloud Computing: IaaS, PaaS, SaaS
- Simulate AWS locally with LocalStack
- Infrastructure as Code with Terraform
- Serverless Lambda functions
- Data Lake architecture (Medallion)

[View Full Exercise](09-cloud-localstack.md){ .md-button }

---

## CAPSTONE PROJECT

### [Capstone Project: Big Data Pipeline with Docker](06-trabajo-final-capstone.md)

!!! success "Integrative Project"
    - **Level:** Advanced
    - **Technologies:** Docker, Apache Spark, PostgreSQL, QoG
    - **Evaluation:** Infrastructure 30% + ETL 25% + Analysis 25% + AI Reflection 20%

**What you'll do:**

- Build Docker infrastructure (Spark + PostgreSQL)
- Design and execute an ETL pipeline with Apache Spark
- Analyze QoG data with your own research question
- Document your learning process with AI

[View Full Assignment](06-trabajo-final-capstone.md){ .md-button .md-button--primary }

---

## Datasets Used

### NYC Taxi & Limousine Commission (TLC)

- **Source:** [NYC Open Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
- **Period:** 2021
- **Records:** 10M+ trips

### Quality of Government (QoG)

- **Source:** [University of Gothenburg](https://www.qog.pol.gu.se/)
- **Variables:** 1289 institutional quality indicators
- **Countries:** 194+ with data since 1946

### AirPassengers

- **Source:** Box & Jenkins (1976)
- **Period:** 1949-1960 (144 monthly observations)
- **Use:** ARIMA/SARIMA time series

---

## How to Work Through Exercises

### Recommended Workflow

1. **Read the full assignment** - Do not start coding without reading everything
2. **Understand the objectives** - What are you expected to achieve?
3. **Create a working branch** - `git checkout -b your-lastname-exercise-XX`
4. **Work in small steps** - Do not try to do everything at once
5. **Test frequently** - Run your code each time you complete a section
6. **Make regular commits** - Save your progress frequently
7. **Push with git push** - When you finish, the system evaluates your PROMPTS.md

---

## Next Steps

Start with the first exercise:

[Exercise 01: Introduction to SQLite](01-introduccion-sqlite.md){ .md-button .md-button--primary }

Or jump to the capstone project:

[Capstone Project: Big Data Pipeline](06-trabajo-final-capstone.md){ .md-button }
