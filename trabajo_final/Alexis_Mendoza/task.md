# Tareas del Proyecto: TF Pipeline BigData con Infraestructura Docker

- [x] Análisis de Requisitos <!-- id: 0 -->
  - [x] Crear estructura de carpetas <!-- id: 1 -->
  - [x] Confirmar etapas del proyecto (basado en la imagen) <!-- id: 2 -->
- [x] Etapa 1: Infraestructura (Docker) <!-- id: 3 -->
  - [x] Definir `Dockerfile` para Spark y TensorFlow <!-- id: 4 -->
  - [x] Definir `docker-compose.yml` (Jupyter, Spark, etc.) <!-- id: 5 -->
  - [x] Verificar levantamiento de servicios <!-- id: 6 -->
- [x] Etapa 2: Ingesta y Procesamiento de Datos <!-- id: 7 -->
  - [x] Descarga/Carga del Dataset <!-- id: 8 -->
  - [x] Limpieza y transformación con PySpark <!-- id: 9 -->
- [x] Etapa 3: Análisis y Modelado (Random Forest en Spark) <!-- id: 10 -->
  - [x] Preparación de datos (VectorAssembler) <!-- id: 11 -->
  - [x] Entrenamiento del modelo (Random Forest) <!-- id: 12 -->
  - [x] Evaluación (Importancia de Variables) <!-- id: 13 -->
- [x] Etapa 4: Documentación y Entrega <!-- id: 14 -->
  - [x] Redactar `README.md` final <!-- id: 15 -->
  - [x] Resumen de planes y justificación <!-- id: 16 -->
- [x] Etapa 6: Seguridad y Acceso <!-- id: 21 -->
  - [x] Implementar pantalla de Login (Usuario/Contraseña) <!-- id: 22 -->
- [x] Etapa 7: Optimización y Rendimiento <!-- id: 23 -->
  - [x] Implementar Caching en Modelo ML (Streamlit) <!-- id: 24 -->
  - [x] Reducir Latencia Artificial en Chatbot <!-- id: 25 -->
- [x] Etapa 8: Exportación y Reportes <!-- id: 26 -->
  - [x] Implementar 'Modo Impresión' (Expandir Tabs) <!-- id: 27 -->
  - [x] Mejorar CSS para impresión (Márgenes, colores) <!-- id: 28 -->
  - [x] Implementar 'Modo Presentación' (Slides Interactivas) <!-- id: 29 -->
- [x] Maintenance <!-- id: 17 -->
  - [x] Update `INSTRUCCIONES_DESPLIEGUE.txt` from GitHub <!-- id: 18 -->
  - [x] Add Doc Link to Dashboard Sidebar <!-- id: 19 -->
